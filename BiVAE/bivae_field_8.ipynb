{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilateral Variational Autoencoder (BiVAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Global Settings and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DanielShen/opt/anaconda3/envs/microsoft_rec/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FM model is only supported on Linux.\n",
      "Windows executable can be found at http://www.libfm.org.\n",
      "System version: 3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:51:59) \n",
      "[Clang 14.0.6 ]\n",
      "PyTorch version: 1.13.1\n",
      "Cornac version: 1.15.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import cornac\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "from recommenders.models.cornac.cornac_utils import predict_ranking\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.utils.constants import SEED\n",
    "from recommenders.utils.constants import (\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_ITEM_COL,\n",
    "    DEFAULT_RATING_COL,\n",
    "    DEFAULT_PREDICTION_COL,\n",
    "    DEFAULT_RELEVANCE_COL,\n",
    "    DEFAULT_SIMILARITY_COL,\n",
    "    DEFAULT_ITEM_FEATURES_COL,\n",
    "    DEFAULT_ITEM_SIM_MEASURE,\n",
    "    DEFAULT_K,\n",
    "    DEFAULT_THRESHOLD,\n",
    ")\n",
    "DEFAULT_RNDCG_MULTIPLIER = 3\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"PyTorch version: {}\".format(torch.__version__))\n",
    "print(\"Cornac version: {}\".format(cornac.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "THIS_ENGINE_NAME = \"bivae_field_8\"\n",
    "\n",
    "DATA_FILE_NAME = \"../Data/20230813T210908_sales_6mo_basic_single_events_removed.csv\"\n",
    "# DATA_FILE_NAME = \"../Data/20230811T031507_sales_12mo_basic_single_events_removed.csv\"\n",
    "# DATA_FILE_NAME = \"../Data/20230809T003134_sales_25mo_basic_single_events_removed.csv\"\n",
    "COL_USER = \"location_id\"\n",
    "COL_ITEM = \"product\"\n",
    "COL_RATING = \"sold_count\"\n",
    "\n",
    "# country\n",
    "COUNTRY = \"nigeria\"\n",
    "\n",
    "# top k items to recommend, for train & test\n",
    "TOP_K_SPLIT_TRAIN_TEST = 10\n",
    "# top k items to recommend, for final product recommendation output\n",
    "TOP_K_WHOLE = 10\n",
    "SAVE_ALL_RECS = False\n",
    "SAVE_NEW_RECS = False\n",
    "\n",
    "# fraction of location_skus to include in training dataset\n",
    "TRAIN_FRAC = 0.75\n",
    "\n",
    "# top MULTIPLIER * k items are considered relevant for nDCG\n",
    "RNDCG_MULTIPLIER = 3\n",
    "\n",
    "# Model parameters\n",
    "LATENT_DIM = 50\n",
    "ENCODER_DIMS = [100]\n",
    "ACT_FUNC = \"tanh\"\n",
    "LIKELIHOOD = \"pois\"\n",
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revised/copied code from packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_rating_column(relevancy_method: str, **kwargs) -> str:\n",
    "    r\"\"\"Helper utility to simplify the arguments of eval metrics\n",
    "    Attemtps to address https://github.com/microsoft/recommenders/issues/1737.\n",
    "\n",
    "    Args:\n",
    "        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n",
    "            top k items are directly provided, so there is no need to compute the relevancy operation.\n",
    "\n",
    "    Returns:\n",
    "        str: rating column name.\n",
    "    \"\"\"\n",
    "    if relevancy_method != \"top_k\":\n",
    "        if \"col_rating\" not in kwargs:\n",
    "            raise ValueError(\"Expected an argument `col_rating` but wasn't found.\")\n",
    "        col_rating = kwargs.get(\"col_rating\")\n",
    "    else:\n",
    "        col_rating = kwargs.get(\"col_rating\", DEFAULT_RATING_COL)\n",
    "    return col_rating\n",
    "\n",
    "\n",
    "def get_top_k_items(\n",
    "    dataframe, col_user=DEFAULT_USER_COL, col_rating=DEFAULT_RATING_COL, k=DEFAULT_K\n",
    "):\n",
    "    \"\"\"Get the input customer-item-rating tuple in the format of Pandas\n",
    "    DataFrame, output a Pandas DataFrame in the dense format of top k items\n",
    "    for each user.\n",
    "\n",
    "    Note:\n",
    "        If it is implicit rating, just append a column of constants to be\n",
    "        ratings.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pandas.DataFrame): DataFrame of rating data (in the format\n",
    "        customerID-itemID-rating)\n",
    "        col_user (str): column name for user\n",
    "        col_rating (str): column name for rating\n",
    "        k (int or None): number of items for each user; None means that the input has already been\n",
    "        filtered out top k items and sorted by ratings and there is no need to do that again.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame of top k items for each user, sorted by `col_user` and `rank`\n",
    "    \"\"\"\n",
    "    # Sort dataframe by col_user and (top k) col_rating\n",
    "    if k is None:\n",
    "        top_k_items = dataframe\n",
    "    else:\n",
    "        top_k_items = (\n",
    "            dataframe.sort_values([col_user, col_rating], ascending=[True, False])\n",
    "            .groupby(col_user, as_index=False)\n",
    "            .head(k)\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "    # Add ranks\n",
    "    top_k_items[\"rank\"] = top_k_items.groupby(col_user, sort=False).cumcount() + 1\n",
    "    return top_k_items\n",
    "\n",
    "\n",
    "def merge_ranking_true_pred_new(\n",
    "    rating_true,\n",
    "    rating_pred,\n",
    "    col_user,\n",
    "    col_item,\n",
    "    col_rating,\n",
    "    col_prediction,\n",
    "    relevancy_method,\n",
    "    k=DEFAULT_K,\n",
    "    rndcg_multiplier=DEFAULT_RNDCG_MULTIPLIER,\n",
    "    threshold=DEFAULT_THRESHOLD,\n",
    "):\n",
    "    \"\"\"Filter truth and prediction data frames on common users\n",
    "\n",
    "    Args:\n",
    "        rating_true (pandas.DataFrame): True DataFrame\n",
    "        rating_pred (pandas.DataFrame): Predicted DataFrame\n",
    "        col_user (str): column name for user\n",
    "        col_item (str): column name for item\n",
    "        col_rating (str): column name for rating\n",
    "        col_prediction (str): column name for prediction\n",
    "        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n",
    "            top k items are directly provided, so there is no need to compute the relevancy operation.\n",
    "        k (int): number of top k items per user (optional)\n",
    "        threshold (float): threshold of top items per user (optional)\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame of recommendation hits, sorted by `col_user` and `rank`\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure the prediction and true data frames have the same set of users\n",
    "    common_users = set(rating_true[col_user]).intersection(set(rating_pred[col_user]))\n",
    "    rating_true_common = rating_true[rating_true[col_user].isin(common_users)]\n",
    "    rating_pred_common = rating_pred[rating_pred[col_user].isin(common_users)]\n",
    "\n",
    "    # Return hit items in prediction data frame with ranking information. This is used for calculating NDCG and MAP.\n",
    "    # Use first to generate unique ranking values for each item. This is to align with the implementation in\n",
    "    # Spark evaluation metrics, where index of each recommended items (the indices are unique to items) is used\n",
    "    # to calculate penalized precision of the ordered items.\n",
    "    if relevancy_method == \"top_k\":\n",
    "        top_k = k\n",
    "    elif relevancy_method == \"by_threshold\":\n",
    "        top_k = threshold\n",
    "    elif relevancy_method is None:\n",
    "        top_k = None\n",
    "    else:\n",
    "        raise NotImplementedError(\"Invalid relevancy_method\")\n",
    "    df_hit = get_top_k_items(\n",
    "        dataframe=rating_pred_common,\n",
    "        col_user=col_user,\n",
    "        col_rating=col_prediction,\n",
    "        k=top_k,\n",
    "    )\n",
    "    rating_true_common_top_mult_k = get_top_k_items(\n",
    "        dataframe=rating_true_common,\n",
    "        col_user=col_user,\n",
    "        col_rating=col_rating,\n",
    "        k=RNDCG_MULTIPLIER * top_k,\n",
    "    )[[col_user, col_item]]\n",
    "    df_hit = pd.merge(df_hit, rating_true_common_top_mult_k, on=[col_user, col_item])[\n",
    "        [col_user, col_item, \"rank\"]\n",
    "    ]\n",
    "\n",
    "    return df_hit\n",
    "\n",
    "\n",
    "def rndcg_at_k(\n",
    "    rating_true,\n",
    "    rating_pred,\n",
    "    col_user=DEFAULT_USER_COL,\n",
    "    col_item=DEFAULT_ITEM_COL,\n",
    "    col_prediction=DEFAULT_PREDICTION_COL,\n",
    "    relevancy_method=\"top_k\",\n",
    "    k=DEFAULT_K,\n",
    "    rndcg_multiplier=RNDCG_MULTIPLIER,\n",
    "    threshold=DEFAULT_THRESHOLD,\n",
    "    score_type=\"binary\",\n",
    "    discfun_type=\"loge\",\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"Normalized Discounted Cumulative Gain (nDCG).\n",
    "\n",
    "    Info: https://en.wikipedia.org/wiki/Discounted_cumulative_gain\n",
    "\n",
    "    Args:\n",
    "        rating_true (pandas.DataFrame): True DataFrame\n",
    "        rating_pred (pandas.DataFrame): Predicted DataFrame\n",
    "        col_user (str): column name for user\n",
    "        col_item (str): column name for item\n",
    "        col_rating (str): column name for rating\n",
    "        col_prediction (str): column name for prediction\n",
    "        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n",
    "            top k items are directly provided, so there is no need to compute the relevancy operation.\n",
    "        k (int): number of top k items per user\n",
    "        threshold (float): threshold of top items per user (optional)\n",
    "        score_type (str): type of relevance scores ['binary', 'raw', 'exp']. With the default option 'binary', the\n",
    "            relevance score is reduced to either 1 (hit) or 0 (miss). Option 'raw' uses the raw relevance score.\n",
    "            Option 'exp' uses (2 ** RAW_RELEVANCE - 1) as the relevance score\n",
    "        discfun_type (str): type of discount function ['loge', 'log2'] used to calculate DCG.\n",
    "\n",
    "    Returns:\n",
    "        float: nDCG at k (min=0, max=1).\n",
    "    \"\"\"\n",
    "    col_rating = _get_rating_column(relevancy_method, **kwargs)\n",
    "    df_hit = merge_ranking_true_pred_new(\n",
    "        rating_true=rating_true,\n",
    "        rating_pred=rating_pred,\n",
    "        col_user=col_user,\n",
    "        col_item=col_item,\n",
    "        col_rating=col_rating,\n",
    "        col_prediction=col_prediction,\n",
    "        relevancy_method=relevancy_method,\n",
    "        k=k,\n",
    "        rndcg_multiplier=rndcg_multiplier,\n",
    "        threshold=threshold,\n",
    "    )\n",
    "\n",
    "    if df_hit.shape[0] == 0:\n",
    "        return 0.0\n",
    "\n",
    "    df_dcg = df_hit.merge(rating_pred, on=[col_user, col_item]).merge(\n",
    "        rating_true, on=[col_user, col_item], how=\"outer\", suffixes=(\"_left\", None)\n",
    "    )\n",
    "\n",
    "    if score_type == \"binary\":\n",
    "        df_dcg[\"rel\"] = 1\n",
    "    elif score_type == \"raw\":\n",
    "        df_dcg[\"rel\"] = df_dcg[col_rating]\n",
    "    elif score_type == \"exp\":\n",
    "        df_dcg[\"rel\"] = 2 ** df_dcg[col_rating] - 1\n",
    "    else:\n",
    "        raise ValueError(\"score_type must be one of 'binary', 'raw', 'exp'\")\n",
    "\n",
    "    if discfun_type == \"loge\":\n",
    "        discfun = np.log\n",
    "    elif discfun_type == \"log2\":\n",
    "        discfun = np.log2\n",
    "    else:\n",
    "        raise ValueError(\"discfun_type must be one of 'loge', 'log2'\")\n",
    "\n",
    "    # Calculate the actual discounted gain for each record\n",
    "    df_dcg[\"dcg\"] = df_dcg[\"rel\"] / discfun(1 + df_dcg[\"rank\"])\n",
    "\n",
    "    # Calculate the ideal discounted gain for each record\n",
    "    df_idcg = df_dcg.sort_values([col_user, col_rating], ascending=False)\n",
    "    df_idcg[\"irank\"] = df_idcg.groupby(col_user, as_index=False, sort=False)[\n",
    "        col_rating\n",
    "    ].rank(\"first\", ascending=False)\n",
    "    df_idcg[\"idcg\"] = df_idcg[\"rel\"] / discfun(1 + df_idcg[\"irank\"])\n",
    "\n",
    "    # Calculate the actual DCG for each user\n",
    "    df_user = df_dcg.groupby(col_user, as_index=False, sort=False).agg({\"dcg\": \"sum\"})\n",
    "\n",
    "    # Calculate the ideal DCG for each user\n",
    "    df_user = df_user.merge(\n",
    "        df_idcg.groupby(col_user, as_index=False, sort=False)\n",
    "        .head(k)\n",
    "        .groupby(col_user, as_index=False, sort=False)\n",
    "        .agg({\"idcg\": \"sum\"}),\n",
    "        on=col_user,\n",
    "    )\n",
    "\n",
    "    # DCG over IDCG is the normalized DCG\n",
    "    df_user[\"ndcg\"] = df_user[\"dcg\"] / df_user[\"idcg\"]\n",
    "    return df_user[\"ndcg\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Data\n",
    "\n",
    "\n",
    "### 1.1 Load and split data\n",
    "\n",
    "To evaluate the performance of item recommendation, we adopted the provided `python_random_split` tool for the consistency.  Data is randomly split into training and test sets with the ratio of 75/25.\n",
    "\n",
    "\n",
    "Note that Cornac also cover different [built-in schemes](https://cornac.readthedocs.io/en/latest/eval_methods.html) for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>product</th>\n",
       "      <th>sold_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"45caa0e9-32b8-4c6d-9730-6b9241c28ab0\"</td>\n",
       "      <td>Coartem 80/480mg Tablets x6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"710ba16d-3f48-401e-b318-eef8d71844ab\"</td>\n",
       "      <td>Coartem 80/480mg Tablets x6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"a613511f-204b-4b4b-ad44-7cb83446c268\"</td>\n",
       "      <td>Coartem 80/480mg Tablets x6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"ce5ab12b-79fd-4584-8328-63a0e8f5c038\"</td>\n",
       "      <td>Coartem 80/480mg Tablets x6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"24dd2d85-3dbf-4171-b564-7cc0d8f92465\"</td>\n",
       "      <td>Coartem 80/480mg Tablets x6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              location_id                      product  \\\n",
       "0  \"45caa0e9-32b8-4c6d-9730-6b9241c28ab0\"  Coartem 80/480mg Tablets x6   \n",
       "1  \"710ba16d-3f48-401e-b318-eef8d71844ab\"  Coartem 80/480mg Tablets x6   \n",
       "2  \"a613511f-204b-4b4b-ad44-7cb83446c268\"  Coartem 80/480mg Tablets x6   \n",
       "3  \"ce5ab12b-79fd-4584-8328-63a0e8f5c038\"  Coartem 80/480mg Tablets x6   \n",
       "4  \"24dd2d85-3dbf-4171-b564-7cc0d8f92465\"  Coartem 80/480mg Tablets x6   \n",
       "\n",
       "   sold_count  \n",
       "0           6  \n",
       "1          11  \n",
       "2           2  \n",
       "3          11  \n",
       "4          10  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_cols = pd.read_csv(DATA_FILE_NAME)\n",
    "data_all_cols = data_all_cols[data_all_cols[\"country\"] == COUNTRY]\n",
    "\n",
    "data = data_all_cols[[COL_USER, COL_ITEM, COL_RATING]]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use quantity sold, not revenue of sales, for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_random_split(data, TRAIN_FRAC, seed = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Cornac Dataset\n",
    "\n",
    "To work with models implemented in Cornac, we need to construct an object from [Dataset](https://cornac.readthedocs.io/en/latest/data.html#module-cornac.data.dataset) class.\n",
    "\n",
    "Dataset Class in Cornac serves as the main object that the models will interact with.  In addition to data transformations, Dataset provides a bunch of useful iterators for looping through the data, as well as supporting different negative sampling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 361\n",
      "Number of items: 1781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DanielShen/opt/anaconda3/envs/microsoft_rec/lib/python3.8/site-packages/cornac/data/dataset.py:361: UserWarning: 29 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    }
   ],
   "source": [
    "train_set = cornac.data.Dataset.from_uir(train.itertuples(index=False), seed=SEED)\n",
    "\n",
    "print('Number of users: {}'.format(train_set.num_users))\n",
    "print('Number of items: {}'.format(train_set.num_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Training\n",
    "\n",
    "The BiVAE has a few important parameters that we need to consider:\n",
    "\n",
    "- `k`: dimension of the latent space (i.e. the size of $\\bf{\\theta}_u$  and  $\\bf{\\beta}_i$ ).\n",
    "- `encoder_structure`: dimension(s) of hidden layer(s) of the user and item encoders.\n",
    "- `act_fn`: non-linear activation function used in the encoders.\n",
    "- `likelihood`: choice of the likelihood function being optimized.\n",
    "- `n_epochs`: number of passes through training data.\n",
    "- `batch_size`: size of mini-batches of data during training.\n",
    "- `learning_rate`: step size in the gradient update rules.\n",
    "\n",
    "To train the model, we simply need to call the `fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivae = cornac.models.BiVAECF(\n",
    "    k=LATENT_DIM,\n",
    "    encoder_structure=ENCODER_DIMS,\n",
    "    act_fn=ACT_FUNC,\n",
    "    likelihood=LIKELIHOOD,\n",
    "    n_epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    seed=SEED,\n",
    "    use_gpu=torch.cuda.is_available(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:22<00:00,  3.50it/s, loss_i=0.469, loss_u=2.55]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 143.0007 seconds for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    bivae.fit(train_set)\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Prediction\n",
    "\n",
    "Now that our model is trained, we can produce the ranked lists for recommendation.  Every recommender models in Cornac provide `rate()` and `rank()` methods for predicting item rated value as well as item ranked list for a given user.  To make use of the current evaluation schemes, we will through `predict()` and `predict_ranking()` functions inside `cornac_utils` to produce the predictions.\n",
    "\n",
    "Note that BiVAE model is effectively designed for item ranking.  Hence, we only measure the performance using ranking metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.4034 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    all_predictions = predict_ranking(bivae, train, usercol=COL_USER, itemcol=COL_ITEM, remove_seen=True)\n",
    "print(\"Took {} seconds for prediction.\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>product</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34826</th>\n",
       "      <td>\"5de61526-8bb1-4c94-a637-30461e397a25\"</td>\n",
       "      <td>Amlosam 5mg Tablet</td>\n",
       "      <td>0.000840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34827</th>\n",
       "      <td>\"5de61526-8bb1-4c94-a637-30461e397a25\"</td>\n",
       "      <td>Wellman Original Tablets x30</td>\n",
       "      <td>0.240650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34828</th>\n",
       "      <td>\"5de61526-8bb1-4c94-a637-30461e397a25\"</td>\n",
       "      <td>Benylin Dry Cough 100ml Syrup</td>\n",
       "      <td>0.260115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34829</th>\n",
       "      <td>\"5de61526-8bb1-4c94-a637-30461e397a25\"</td>\n",
       "      <td>Doxycap 100mg Capsules x100</td>\n",
       "      <td>0.109588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34830</th>\n",
       "      <td>\"5de61526-8bb1-4c94-a637-30461e397a25\"</td>\n",
       "      <td>Durex Extra Safe x3[D/C]</td>\n",
       "      <td>0.083123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  location_id                        product  \\\n",
       "34826  \"5de61526-8bb1-4c94-a637-30461e397a25\"             Amlosam 5mg Tablet   \n",
       "34827  \"5de61526-8bb1-4c94-a637-30461e397a25\"   Wellman Original Tablets x30   \n",
       "34828  \"5de61526-8bb1-4c94-a637-30461e397a25\"  Benylin Dry Cough 100ml Syrup   \n",
       "34829  \"5de61526-8bb1-4c94-a637-30461e397a25\"    Doxycap 100mg Capsules x100   \n",
       "34830  \"5de61526-8bb1-4c94-a637-30461e397a25\"       Durex Extra Safe x3[D/C]   \n",
       "\n",
       "       prediction  \n",
       "34826    0.000840  \n",
       "34827    0.240650  \n",
       "34828    0.260115  \n",
       "34829    0.109588  \n",
       "34830    0.083123  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>product</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103108</th>\n",
       "      <td>\"72d85136-5b62-48d2-a677-c5b10e091f2a\"</td>\n",
       "      <td>Keytifen Eye Drops</td>\n",
       "      <td>7.782439e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103678</th>\n",
       "      <td>\"72d85136-5b62-48d2-a677-c5b10e091f2a\"</td>\n",
       "      <td>Jawaclox Drops</td>\n",
       "      <td>7.782439e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103625</th>\n",
       "      <td>\"72d85136-5b62-48d2-a677-c5b10e091f2a\"</td>\n",
       "      <td>Cartol 200mg Tablet x100</td>\n",
       "      <td>7.782439e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103506</th>\n",
       "      <td>\"72d85136-5b62-48d2-a677-c5b10e091f2a\"</td>\n",
       "      <td>Surexime 60ml Suspension</td>\n",
       "      <td>7.782439e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104197</th>\n",
       "      <td>\"72d85136-5b62-48d2-a677-c5b10e091f2a\"</td>\n",
       "      <td>Kifaru 100mg Tablet</td>\n",
       "      <td>8.562724e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   location_id                   product  \\\n",
       "103108  \"72d85136-5b62-48d2-a677-c5b10e091f2a\"        Keytifen Eye Drops   \n",
       "103678  \"72d85136-5b62-48d2-a677-c5b10e091f2a\"            Jawaclox Drops   \n",
       "103625  \"72d85136-5b62-48d2-a677-c5b10e091f2a\"  Cartol 200mg Tablet x100   \n",
       "103506  \"72d85136-5b62-48d2-a677-c5b10e091f2a\"  Surexime 60ml Suspension   \n",
       "104197  \"72d85136-5b62-48d2-a677-c5b10e091f2a\"       Kifaru 100mg Tablet   \n",
       "\n",
       "          prediction  \n",
       "103108  7.782439e-07  \n",
       "103678  7.782439e-07  \n",
       "103625  7.782439e-07  \n",
       "103506  7.782439e-07  \n",
       "104197  8.562724e-07  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore min\n",
    "all_predictions.sort_values(by=\"prediction\", ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>product</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47590</th>\n",
       "      <td>\"53adbd2d-b6ed-4d1f-89be-b21832b4fa21\"</td>\n",
       "      <td>Ciprotab 500mg Tablets x10</td>\n",
       "      <td>0.998725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185769</th>\n",
       "      <td>\"88395a11-a04e-437d-ade6-37b12c54c783\"</td>\n",
       "      <td>Artequick 62.5/375mg Tablets x4</td>\n",
       "      <td>0.994728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55318</th>\n",
       "      <td>\"96bdd2f2-044d-4060-95d2-e653045b2f6f\"</td>\n",
       "      <td>De-Deon's Syrup 280ml</td>\n",
       "      <td>0.993930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47706</th>\n",
       "      <td>\"53adbd2d-b6ed-4d1f-89be-b21832b4fa21\"</td>\n",
       "      <td>Vasoprin 75mg Tablets x100</td>\n",
       "      <td>0.992954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244252</th>\n",
       "      <td>\"38b5a6fc-63ae-4a92-812f-7d97d1308d0a\"</td>\n",
       "      <td>Amatem 80/480 Softgel x6</td>\n",
       "      <td>0.992365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   location_id  \\\n",
       "47590   \"53adbd2d-b6ed-4d1f-89be-b21832b4fa21\"   \n",
       "185769  \"88395a11-a04e-437d-ade6-37b12c54c783\"   \n",
       "55318   \"96bdd2f2-044d-4060-95d2-e653045b2f6f\"   \n",
       "47706   \"53adbd2d-b6ed-4d1f-89be-b21832b4fa21\"   \n",
       "244252  \"38b5a6fc-63ae-4a92-812f-7d97d1308d0a\"   \n",
       "\n",
       "                                product  prediction  \n",
       "47590        Ciprotab 500mg Tablets x10    0.998725  \n",
       "185769  Artequick 62.5/375mg Tablets x4    0.994728  \n",
       "55318             De-Deon's Syrup 280ml    0.993930  \n",
       "47706        Vasoprin 75mg Tablets x100    0.992954  \n",
       "244252         Amatem 80/480 Softgel x6    0.992365  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore max\n",
    "all_predictions.sort_values(by=\"prediction\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Evaluation / Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_map = map_at_k(test, all_predictions, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_SPLIT_TRAIN_TEST)\n",
    "# eval_ndcg = ndcg_at_k(test, all_predictions, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_SPLIT_TRAIN_TEST)\n",
    "# eval_rndcg = rndcg_at_k(test, all_predictions, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_SPLIT_TRAIN_TEST, rndcg_multiplier=RNDCG_MULTIPLIER)\n",
    "# eval_precision = precision_at_k(test, all_predictions, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_SPLIT_TRAIN_TEST)\n",
    "# eval_recall = recall_at_k(test, all_predictions, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_SPLIT_TRAIN_TEST)\n",
    "\n",
    "# print(\"MAP:\\t%f\" % eval_map,\n",
    "#       \"NDCG:\\t%f\" % eval_ndcg,\n",
    "#       \"RNDCG:\\t%f\" % eval_rndcg,\n",
    "#       \"Precision@K:\\t%f\" % eval_precision,\n",
    "#       \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Train, Predict, and Evaluate on Whole Dataset\n",
    "\n",
    "Earlier, we had split train (for model training) and test (for evaluation). In implementation, we have train = whole dataset, and we can evaluate on test = whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 361\n",
      "Number of items: 1863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DanielShen/opt/anaconda3/envs/microsoft_rec/lib/python3.8/site-packages/cornac/data/dataset.py:361: UserWarning: 50 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n",
      "100%|██████████| 500/500 [02:34<00:00,  3.23it/s, loss_i=0.537, loss_u=2.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 154.8771 seconds for training.\n",
      "Took 0.1545 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "## Data\n",
    "data_set = cornac.data.Dataset.from_uir(data.itertuples(index=False), seed=SEED)\n",
    "print('Number of users: {}'.format(data_set.num_users))\n",
    "print('Number of items: {}'.format(data_set.num_items))\n",
    "\n",
    "## Train\n",
    "bivae_whole = cornac.models.BiVAECF(\n",
    "    k=LATENT_DIM,\n",
    "    encoder_structure=ENCODER_DIMS,\n",
    "    act_fn=ACT_FUNC,\n",
    "    likelihood=LIKELIHOOD,\n",
    "    n_epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    seed=SEED,\n",
    "    use_gpu=torch.cuda.is_available(),\n",
    "    verbose=True\n",
    ")\n",
    "with Timer() as t:\n",
    "    bivae_whole.fit(data_set)\n",
    "print(\"Took {} seconds for training.\".format(t))\n",
    "\n",
    "## Predict\n",
    "with Timer() as t:\n",
    "    all_predictions_whole = predict_ranking(bivae, data, usercol=COL_USER, itemcol=COL_ITEM, remove_seen=False)\n",
    "print(\"Took {} seconds for prediction.\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>product</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75543</th>\n",
       "      <td>\"72d85136-5b62-48d2-a677-c5b10e091f2a\"</td>\n",
       "      <td>Surexime 60ml Suspension</td>\n",
       "      <td>7.782439e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75716</th>\n",
       "      <td>\"72d85136-5b62-48d2-a677-c5b10e091f2a\"</td>\n",
       "      <td>Jawaclox Drops</td>\n",
       "      <td>7.782439e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75662</th>\n",
       "      <td>\"72d85136-5b62-48d2-a677-c5b10e091f2a\"</td>\n",
       "      <td>Cartol 200mg Tablet x100</td>\n",
       "      <td>7.782439e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75123</th>\n",
       "      <td>\"72d85136-5b62-48d2-a677-c5b10e091f2a\"</td>\n",
       "      <td>Keytifen Eye Drops</td>\n",
       "      <td>7.782439e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76235</th>\n",
       "      <td>\"72d85136-5b62-48d2-a677-c5b10e091f2a\"</td>\n",
       "      <td>Kifaru 100mg Tablet</td>\n",
       "      <td>8.562724e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  location_id                   product  \\\n",
       "75543  \"72d85136-5b62-48d2-a677-c5b10e091f2a\"  Surexime 60ml Suspension   \n",
       "75716  \"72d85136-5b62-48d2-a677-c5b10e091f2a\"            Jawaclox Drops   \n",
       "75662  \"72d85136-5b62-48d2-a677-c5b10e091f2a\"  Cartol 200mg Tablet x100   \n",
       "75123  \"72d85136-5b62-48d2-a677-c5b10e091f2a\"        Keytifen Eye Drops   \n",
       "76235  \"72d85136-5b62-48d2-a677-c5b10e091f2a\"       Kifaru 100mg Tablet   \n",
       "\n",
       "         prediction  \n",
       "75543  7.782439e-07  \n",
       "75716  7.782439e-07  \n",
       "75662  7.782439e-07  \n",
       "75123  7.782439e-07  \n",
       "76235  8.562724e-07  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore min\n",
    "all_predictions_whole.sort_values(by=\"prediction\", ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>product</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14481</th>\n",
       "      <td>\"53adbd2d-b6ed-4d1f-89be-b21832b4fa21\"</td>\n",
       "      <td>Ciprotab 500mg Tablets x10</td>\n",
       "      <td>0.998725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23386</th>\n",
       "      <td>\"96bdd2f2-044d-4060-95d2-e653045b2f6f\"</td>\n",
       "      <td>Ciprotab 500mg Tablets x10</td>\n",
       "      <td>0.998623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165866</th>\n",
       "      <td>\"88395a11-a04e-437d-ade6-37b12c54c783\"</td>\n",
       "      <td>Ciprotab 500mg Tablets x10</td>\n",
       "      <td>0.998487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228201</th>\n",
       "      <td>\"38b5a6fc-63ae-4a92-812f-7d97d1308d0a\"</td>\n",
       "      <td>Ciprotab 500mg Tablets x10</td>\n",
       "      <td>0.998449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219296</th>\n",
       "      <td>\"bc1f9ebd-8c5b-48aa-9880-53b635a6deb8\"</td>\n",
       "      <td>Ciprotab 500mg Tablets x10</td>\n",
       "      <td>0.997716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   location_id                     product  \\\n",
       "14481   \"53adbd2d-b6ed-4d1f-89be-b21832b4fa21\"  Ciprotab 500mg Tablets x10   \n",
       "23386   \"96bdd2f2-044d-4060-95d2-e653045b2f6f\"  Ciprotab 500mg Tablets x10   \n",
       "165866  \"88395a11-a04e-437d-ade6-37b12c54c783\"  Ciprotab 500mg Tablets x10   \n",
       "228201  \"38b5a6fc-63ae-4a92-812f-7d97d1308d0a\"  Ciprotab 500mg Tablets x10   \n",
       "219296  \"bc1f9ebd-8c5b-48aa-9880-53b635a6deb8\"  Ciprotab 500mg Tablets x10   \n",
       "\n",
       "        prediction  \n",
       "14481     0.998725  \n",
       "23386     0.998623  \n",
       "165866    0.998487  \n",
       "228201    0.998449  \n",
       "219296    0.997716  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore max\n",
    "all_predictions_whole.sort_values(by=\"prediction\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP_K_WHOLE = 100\n",
    "# RNDCG_MULTIPLIER = 3\n",
    "\n",
    "## Evaluate\n",
    "# eval_map_whole = map_at_k(data, all_predictions_whole, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_WHOLE)\n",
    "# eval_ndcg_whole = ndcg_at_k(data, all_predictions_whole, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_WHOLE)\n",
    "# eval_rndcg_whole = rndcg_at_k(data, all_predictions_whole, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_WHOLE, rndcg_multiplier=RNDCG_MULTIPLIER)\n",
    "# eval_precision_whole = precision_at_k(data, all_predictions_whole, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_WHOLE)\n",
    "# eval_recall_whole = recall_at_k(data, all_predictions_whole, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_WHOLE)\n",
    "\n",
    "# print(\"MAP:\\t%f\" % eval_map_whole,\n",
    "#       \"NDCG:\\t%f\" % eval_ndcg_whole,\n",
    "#       \"RNDCG:\\t%f\" % eval_rndcg_whole,\n",
    "#       \"Precision@K:\\t%f\" % eval_precision_whole,\n",
    "#       \"Recall@K:\\t%f\" % eval_recall_whole, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE_ALL_RECS = True\n",
    "# SAVE_NEW_RECS = True\n",
    "\n",
    "## Save recommendations\n",
    "# if SAVE_ALL_RECS:\n",
    "#     top_k_predictions_whole = get_top_k_items(all_predictions_whole, col_user=COL_USER, col_rating=DEFAULT_PREDICTION_COL, k=TOP_K_WHOLE)\n",
    "#     top_k_predictions_whole.drop(DEFAULT_PREDICTION_COL, axis = 1, inplace = True)\n",
    "#     # add column of true sales and rank of predicted products\n",
    "#     top_all_true = get_top_k_items(data, col_user=COL_USER, col_rating=COL_RATING, k=data_set.num_items)\n",
    "#     top_k_predictions_whole = top_k_predictions_whole.merge(top_all_true, how = 'left', on = [COL_USER, COL_ITEM], suffixes = (None, \"_true\"))\n",
    "#     top_k_predictions_whole[\"rank_true\"] = top_k_predictions_whole[\"rank_true\"].convert_dtypes()\n",
    "#     top_k_predictions_whole.rename(columns = {COL_ITEM: \"predicted \" + COL_ITEM, COL_RATING: \"predicted \" + COL_ITEM + \"'s true \" + COL_RATING, \"rank_true\": \"predicted \" + COL_ITEM + \"'s true rank\"}, inplace = True)\n",
    "#     # add columns of true top-ranked products\n",
    "#     top_all_true.rename(columns = {COL_ITEM: \"true \" + COL_ITEM, COL_RATING: \"true \"  + COL_ITEM + \"'s \" + COL_RATING}, inplace = True)\n",
    "#     top_k_predictions_whole = top_k_predictions_whole.merge(top_all_true, how = 'left', on = [COL_USER, 'rank'])\n",
    "#     # reorder columns\n",
    "#     top_k_predictions_whole = top_k_predictions_whole[[COL_USER, \"rank\", \"true \" + COL_ITEM, \"true \" + COL_ITEM + \"'s \" + COL_RATING, \"predicted \" + COL_ITEM, \"predicted \"  + COL_ITEM + \"'s true \" + COL_RATING, \"predicted \" + COL_ITEM + \"'s true rank\"]]\n",
    "#     # save to csv\n",
    "#     top_k_predictions_whole.to_csv(THIS_ENGINE_NAME + \"_\" + COUNTRY + \"_top_\" + str(TOP_K_WHOLE) + \"_all_prod_recs.csv\")\n",
    "# if SAVE_NEW_RECS:\n",
    "#     new_predictions_whole = all_predictions_whole.merge(data, on=[COL_USER,COL_ITEM], indicator=True, how=\"left\").query('_merge==\"left_only\"').drop('_merge', axis=1).drop([COL_RATING], axis=1)\n",
    "#     top_k_predictions_whole = get_top_k_items(new_predictions_whole, col_user=COL_USER, col_rating=DEFAULT_PREDICTION_COL, k=TOP_K_WHOLE)\n",
    "#     top_k_predictions_whole.drop(DEFAULT_PREDICTION_COL, axis = 1, inplace = True)\n",
    "#     top_k_predictions_whole.rename(columns = {COL_ITEM: \"predicted new \" + COL_ITEM}, inplace=True)\n",
    "#     top_k_true = get_top_k_items(data, col_user=COL_USER, col_rating=COL_RATING, k=TOP_K_WHOLE)\n",
    "#     top_k_true.rename(columns = {COL_ITEM: \"true \" + COL_ITEM, COL_RATING: \"true \"  + COL_ITEM + \"'s \" + COL_RATING}, inplace = True)\n",
    "#     top_k_predictions_whole = top_k_predictions_whole.merge(top_k_true, on = [COL_USER, 'rank'])\n",
    "#     top_k_predictions_whole = top_k_predictions_whole[[COL_USER, \"rank\", \"true \" + COL_ITEM, \"true \" + COL_ITEM + \"'s \" + COL_RATING, \"predicted new \" + COL_ITEM]]\n",
    "#     top_k_predictions_whole.to_csv(THIS_ENGINE_NAME + \"_\" + COUNTRY + \"_top_\" + str(TOP_K_WHOLE) + \"_new_prod_recs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
