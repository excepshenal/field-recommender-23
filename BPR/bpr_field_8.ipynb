{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Personalized Ranking (BPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Global Settings and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DanielShen/opt/anaconda3/envs/microsoft_rec/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FM model is only supported on Linux.\n",
      "Windows executable can be found at http://www.libfm.org.\n",
      "System version: 3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:51:59) \n",
      "[Clang 14.0.6 ]\n",
      "Cornac version: 1.15.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import cornac\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "from recommenders.models.cornac.cornac_utils import predict_ranking\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.utils.constants import SEED\n",
    "from recommenders.utils.constants import (\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_ITEM_COL,\n",
    "    DEFAULT_RATING_COL,\n",
    "    DEFAULT_PREDICTION_COL,\n",
    "    DEFAULT_RELEVANCE_COL,\n",
    "    DEFAULT_SIMILARITY_COL,\n",
    "    DEFAULT_ITEM_FEATURES_COL,\n",
    "    DEFAULT_ITEM_SIM_MEASURE,\n",
    "    DEFAULT_K,\n",
    "    DEFAULT_THRESHOLD,\n",
    ")\n",
    "DEFAULT_RNDCG_MULTIPLIER = 3\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Cornac version: {}\".format(cornac.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "THIS_ENGINE_NAME = \"bpr_field_8\"\n",
    "\n",
    "# DATA_FILE_NAME = \"../Data/20230813T210908_sales_6mo_basic_single_events_removed.csv\"\n",
    "# DATA_FILE_NAME = \"../Data/20230811T031507_sales_12mo_basic_single_events_removed.csv\"\n",
    "DATA_FILE_NAME = \"../Data/20230809T003134_sales_25mo_basic_single_events_removed.csv\"\n",
    "COL_USER = \"location_id\"\n",
    "COL_ITEM = \"product\"\n",
    "COL_RATING = \"sold_count\"\n",
    "\n",
    "# country\n",
    "COUNTRY = \"nigeria\"\n",
    "\n",
    "# top k items to recommend, for train & test\n",
    "TOP_K_SPLIT_TRAIN_TEST = 10\n",
    "# top k items to recommend, for final product recommendation output\n",
    "TOP_K_WHOLE = 10\n",
    "SAVE_ALL_RECS = False\n",
    "SAVE_NEW_RECS = False\n",
    "\n",
    "# fraction of location_skus to include in training dataset\n",
    "TRAIN_FRAC = 0.75\n",
    "\n",
    "# top MULTIPLIER * k items are considered relevant for nDCG\n",
    "RNDCG_MULTIPLIER = 3\n",
    "\n",
    "# Model parameters\n",
    "NUM_FACTORS = 200\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 0.01\n",
    "LAMBDA_REG = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revised/copied code from packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_rating_column(relevancy_method: str, **kwargs) -> str:\n",
    "    r\"\"\"Helper utility to simplify the arguments of eval metrics\n",
    "    Attemtps to address https://github.com/microsoft/recommenders/issues/1737.\n",
    "\n",
    "    Args:\n",
    "        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n",
    "            top k items are directly provided, so there is no need to compute the relevancy operation.\n",
    "\n",
    "    Returns:\n",
    "        str: rating column name.\n",
    "    \"\"\"\n",
    "    if relevancy_method != \"top_k\":\n",
    "        if \"col_rating\" not in kwargs:\n",
    "            raise ValueError(\"Expected an argument `col_rating` but wasn't found.\")\n",
    "        col_rating = kwargs.get(\"col_rating\")\n",
    "    else:\n",
    "        col_rating = kwargs.get(\"col_rating\", DEFAULT_RATING_COL)\n",
    "    return col_rating\n",
    "\n",
    "\n",
    "def get_top_k_items(\n",
    "    dataframe, col_user=DEFAULT_USER_COL, col_rating=DEFAULT_RATING_COL, k=DEFAULT_K\n",
    "):\n",
    "    \"\"\"Get the input customer-item-rating tuple in the format of Pandas\n",
    "    DataFrame, output a Pandas DataFrame in the dense format of top k items\n",
    "    for each user.\n",
    "\n",
    "    Note:\n",
    "        If it is implicit rating, just append a column of constants to be\n",
    "        ratings.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pandas.DataFrame): DataFrame of rating data (in the format\n",
    "        customerID-itemID-rating)\n",
    "        col_user (str): column name for user\n",
    "        col_rating (str): column name for rating\n",
    "        k (int or None): number of items for each user; None means that the input has already been\n",
    "        filtered out top k items and sorted by ratings and there is no need to do that again.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame of top k items for each user, sorted by `col_user` and `rank`\n",
    "    \"\"\"\n",
    "    # Sort dataframe by col_user and (top k) col_rating\n",
    "    if k is None:\n",
    "        top_k_items = dataframe\n",
    "    else:\n",
    "        top_k_items = (\n",
    "            dataframe.sort_values([col_user, col_rating], ascending=[True, False])\n",
    "            .groupby(col_user, as_index=False)\n",
    "            .head(k)\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "    # Add ranks\n",
    "    top_k_items[\"rank\"] = top_k_items.groupby(col_user, sort=False).cumcount() + 1\n",
    "    return top_k_items\n",
    "\n",
    "\n",
    "def merge_ranking_true_pred_new(\n",
    "    rating_true,\n",
    "    rating_pred,\n",
    "    col_user,\n",
    "    col_item,\n",
    "    col_rating,\n",
    "    col_prediction,\n",
    "    relevancy_method,\n",
    "    k=DEFAULT_K,\n",
    "    rndcg_multiplier=DEFAULT_RNDCG_MULTIPLIER,\n",
    "    threshold=DEFAULT_THRESHOLD,\n",
    "):\n",
    "    \"\"\"Filter truth and prediction data frames on common users\n",
    "\n",
    "    Args:\n",
    "        rating_true (pandas.DataFrame): True DataFrame\n",
    "        rating_pred (pandas.DataFrame): Predicted DataFrame\n",
    "        col_user (str): column name for user\n",
    "        col_item (str): column name for item\n",
    "        col_rating (str): column name for rating\n",
    "        col_prediction (str): column name for prediction\n",
    "        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n",
    "            top k items are directly provided, so there is no need to compute the relevancy operation.\n",
    "        k (int): number of top k items per user (optional)\n",
    "        threshold (float): threshold of top items per user (optional)\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame of recommendation hits, sorted by `col_user` and `rank`\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure the prediction and true data frames have the same set of users\n",
    "    common_users = set(rating_true[col_user]).intersection(set(rating_pred[col_user]))\n",
    "    rating_true_common = rating_true[rating_true[col_user].isin(common_users)]\n",
    "    rating_pred_common = rating_pred[rating_pred[col_user].isin(common_users)]\n",
    "\n",
    "    # Return hit items in prediction data frame with ranking information. This is used for calculating NDCG and MAP.\n",
    "    # Use first to generate unique ranking values for each item. This is to align with the implementation in\n",
    "    # Spark evaluation metrics, where index of each recommended items (the indices are unique to items) is used\n",
    "    # to calculate penalized precision of the ordered items.\n",
    "    if relevancy_method == \"top_k\":\n",
    "        top_k = k\n",
    "    elif relevancy_method == \"by_threshold\":\n",
    "        top_k = threshold\n",
    "    elif relevancy_method is None:\n",
    "        top_k = None\n",
    "    else:\n",
    "        raise NotImplementedError(\"Invalid relevancy_method\")\n",
    "    df_hit = get_top_k_items(\n",
    "        dataframe=rating_pred_common,\n",
    "        col_user=col_user,\n",
    "        col_rating=col_prediction,\n",
    "        k=top_k,\n",
    "    )\n",
    "    rating_true_common_top_mult_k = get_top_k_items(\n",
    "        dataframe=rating_true_common,\n",
    "        col_user=col_user,\n",
    "        col_rating=col_rating,\n",
    "        k=RNDCG_MULTIPLIER * top_k,\n",
    "    )[[col_user, col_item]]\n",
    "    df_hit = pd.merge(df_hit, rating_true_common_top_mult_k, on=[col_user, col_item])[\n",
    "        [col_user, col_item, \"rank\"]\n",
    "    ]\n",
    "\n",
    "    return df_hit\n",
    "\n",
    "\n",
    "def rndcg_at_k(\n",
    "    rating_true,\n",
    "    rating_pred,\n",
    "    col_user=DEFAULT_USER_COL,\n",
    "    col_item=DEFAULT_ITEM_COL,\n",
    "    col_prediction=DEFAULT_PREDICTION_COL,\n",
    "    relevancy_method=\"top_k\",\n",
    "    k=DEFAULT_K,\n",
    "    rndcg_multiplier=RNDCG_MULTIPLIER,\n",
    "    threshold=DEFAULT_THRESHOLD,\n",
    "    score_type=\"binary\",\n",
    "    discfun_type=\"loge\",\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"Normalized Discounted Cumulative Gain (nDCG).\n",
    "\n",
    "    Info: https://en.wikipedia.org/wiki/Discounted_cumulative_gain\n",
    "\n",
    "    Args:\n",
    "        rating_true (pandas.DataFrame): True DataFrame\n",
    "        rating_pred (pandas.DataFrame): Predicted DataFrame\n",
    "        col_user (str): column name for user\n",
    "        col_item (str): column name for item\n",
    "        col_rating (str): column name for rating\n",
    "        col_prediction (str): column name for prediction\n",
    "        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n",
    "            top k items are directly provided, so there is no need to compute the relevancy operation.\n",
    "        k (int): number of top k items per user\n",
    "        threshold (float): threshold of top items per user (optional)\n",
    "        score_type (str): type of relevance scores ['binary', 'raw', 'exp']. With the default option 'binary', the\n",
    "            relevance score is reduced to either 1 (hit) or 0 (miss). Option 'raw' uses the raw relevance score.\n",
    "            Option 'exp' uses (2 ** RAW_RELEVANCE - 1) as the relevance score\n",
    "        discfun_type (str): type of discount function ['loge', 'log2'] used to calculate DCG.\n",
    "\n",
    "    Returns:\n",
    "        float: nDCG at k (min=0, max=1).\n",
    "    \"\"\"\n",
    "    col_rating = _get_rating_column(relevancy_method, **kwargs)\n",
    "    df_hit = merge_ranking_true_pred_new(\n",
    "        rating_true=rating_true,\n",
    "        rating_pred=rating_pred,\n",
    "        col_user=col_user,\n",
    "        col_item=col_item,\n",
    "        col_rating=col_rating,\n",
    "        col_prediction=col_prediction,\n",
    "        relevancy_method=relevancy_method,\n",
    "        k=k,\n",
    "        rndcg_multiplier=rndcg_multiplier,\n",
    "        threshold=threshold,\n",
    "    )\n",
    "\n",
    "    if df_hit.shape[0] == 0:\n",
    "        return 0.0\n",
    "\n",
    "    df_dcg = df_hit.merge(rating_pred, on=[col_user, col_item]).merge(\n",
    "        rating_true, on=[col_user, col_item], how=\"outer\", suffixes=(\"_left\", None)\n",
    "    )\n",
    "\n",
    "    if score_type == \"binary\":\n",
    "        df_dcg[\"rel\"] = 1\n",
    "    elif score_type == \"raw\":\n",
    "        df_dcg[\"rel\"] = df_dcg[col_rating]\n",
    "    elif score_type == \"exp\":\n",
    "        df_dcg[\"rel\"] = 2 ** df_dcg[col_rating] - 1\n",
    "    else:\n",
    "        raise ValueError(\"score_type must be one of 'binary', 'raw', 'exp'\")\n",
    "\n",
    "    if discfun_type == \"loge\":\n",
    "        discfun = np.log\n",
    "    elif discfun_type == \"log2\":\n",
    "        discfun = np.log2\n",
    "    else:\n",
    "        raise ValueError(\"discfun_type must be one of 'loge', 'log2'\")\n",
    "\n",
    "    # Calculate the actual discounted gain for each record\n",
    "    df_dcg[\"dcg\"] = df_dcg[\"rel\"] / discfun(1 + df_dcg[\"rank\"])\n",
    "\n",
    "    # Calculate the ideal discounted gain for each record\n",
    "    df_idcg = df_dcg.sort_values([col_user, col_rating], ascending=False)\n",
    "    df_idcg[\"irank\"] = df_idcg.groupby(col_user, as_index=False, sort=False)[\n",
    "        col_rating\n",
    "    ].rank(\"first\", ascending=False)\n",
    "    df_idcg[\"idcg\"] = df_idcg[\"rel\"] / discfun(1 + df_idcg[\"irank\"])\n",
    "\n",
    "    # Calculate the actual DCG for each user\n",
    "    df_user = df_dcg.groupby(col_user, as_index=False, sort=False).agg({\"dcg\": \"sum\"})\n",
    "\n",
    "    # Calculate the ideal DCG for each user\n",
    "    df_user = df_user.merge(\n",
    "        df_idcg.groupby(col_user, as_index=False, sort=False)\n",
    "        .head(k)\n",
    "        .groupby(col_user, as_index=False, sort=False)\n",
    "        .agg({\"idcg\": \"sum\"}),\n",
    "        on=col_user,\n",
    "    )\n",
    "\n",
    "    # DCG over IDCG is the normalized DCG\n",
    "    df_user[\"ndcg\"] = df_user[\"dcg\"] / df_user[\"idcg\"]\n",
    "    return df_user[\"ndcg\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Data\n",
    "\n",
    "\n",
    "### 1.1 Load and split data\n",
    "\n",
    "To evaluate the performance of item recommendation, we adopted the provided `python_random_split` tool for the consistency.  Data is randomly split into training and test sets with the ratio of 75/25.\n",
    "\n",
    "\n",
    "Note that Cornac also cover different [built-in schemes](https://cornac.readthedocs.io/en/latest/eval_methods.html) for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>product</th>\n",
       "      <th>sold_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"01cdce0f-96cb-4706-8eb5-ca1c3e52cee2\"</td>\n",
       "      <td>Coartem 80/480mg Tablets x6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"02c51d76-3932-45d6-84c8-e40917ceda22\"</td>\n",
       "      <td>Coartem 80/480mg Tablets x6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"03550e79-e8f4-475c-be2b-ea978a197f29\"</td>\n",
       "      <td>Coartem 80/480mg Tablets x6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"04f7dedc-48c3-4568-b758-6e877e6aec15\"</td>\n",
       "      <td>Coartem 80/480mg Tablets x6</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"05b94f69-344f-4db7-ae3b-1c02cb2d3bdc\"</td>\n",
       "      <td>Coartem 80/480mg Tablets x6</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              location_id                      product  \\\n",
       "0  \"01cdce0f-96cb-4706-8eb5-ca1c3e52cee2\"  Coartem 80/480mg Tablets x6   \n",
       "1  \"02c51d76-3932-45d6-84c8-e40917ceda22\"  Coartem 80/480mg Tablets x6   \n",
       "2  \"03550e79-e8f4-475c-be2b-ea978a197f29\"  Coartem 80/480mg Tablets x6   \n",
       "3  \"04f7dedc-48c3-4568-b758-6e877e6aec15\"  Coartem 80/480mg Tablets x6   \n",
       "4  \"05b94f69-344f-4db7-ae3b-1c02cb2d3bdc\"  Coartem 80/480mg Tablets x6   \n",
       "\n",
       "   sold_count  \n",
       "0           9  \n",
       "1          12  \n",
       "2           8  \n",
       "3         198  \n",
       "4         339  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_cols = pd.read_csv(DATA_FILE_NAME)\n",
    "data_all_cols = data_all_cols[data_all_cols[\"country\"] == COUNTRY]\n",
    "\n",
    "data = data_all_cols[[COL_USER, COL_ITEM, COL_RATING]]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use quantity sold, not revenue of sales, for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_random_split(data, TRAIN_FRAC, seed = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Cornac Dataset\n",
    "\n",
    "To work with models implemented in Cornac, we need to construct an object from [Dataset](https://cornac.readthedocs.io/en/latest/data.html#module-cornac.data.dataset) class.\n",
    "\n",
    "Dataset Class in Cornac serves as the main object that the models will interact with.  In addition to data transformations, Dataset provides a bunch of useful iterators for looping through the data, as well as supporting different negative sampling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 960\n",
      "Number of items: 2072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DanielShen/opt/anaconda3/envs/microsoft_rec/lib/python3.8/site-packages/cornac/data/dataset.py:361: UserWarning: 311 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    }
   ],
   "source": [
    "train_set = cornac.data.Dataset.from_uir(train.itertuples(index=False), seed=SEED)\n",
    "\n",
    "print('Number of users: {}'.format(train_set.num_users))\n",
    "print('Number of items: {}'.format(train_set.num_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Training\n",
    "\n",
    "The BPR has a few important parameters that we need to consider:\n",
    "\n",
    "- `k`: controls the dimension of the latent space (i.e. the size of the vectors  $w_u$  and  $h_i$ ).\n",
    "- `max_iter`: defines the number of iterations of the SGD procedure.\n",
    "- `learning_rate`: controls the step size $\\alpha$ in the gradient update rules.\n",
    "- `lambda_reg`: controls the L2-Regularization $\\lambda$ in the objective function.\n",
    "\n",
    "Note that different values of `k` and `max_iter` will affect the training time.\n",
    "\n",
    "We will here set `k` to 200, `max_iter` to 100, `learning_rate` to 0.01, and `lambda_reg` to 0.001. To train the model, we simply need to call the `fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr = cornac.models.BPR(\n",
    "    k=NUM_FACTORS,\n",
    "    max_iter=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    lambda_reg=LAMBDA_REG,\n",
    "    verbose=True,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 30.64it/s, correct=95.18%, skipped=11.17%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished!\n",
      "Took 3.2991 seconds for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    bpr.fit(train_set)\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Prediction\n",
    "\n",
    "Now that our model is trained, we can produce the ranked lists for recommendation.  Every recommender models in Cornac provide `rate()` and `rank()` methods for predicting item rated value as well as item ranked list for a given user.  To make use of the current evaluation schemes, we will through `predict()` and `predict_ranking()` functions inside `cornac_utils` to produce the predictions.\n",
    "\n",
    "Note that BPR model is effectively designed for item ranking.  Hence, we only measure the performance using ranking metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 1.2418 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    all_predictions = predict_ranking(bpr, train, usercol=COL_USER, itemcol=COL_ITEM, remove_seen=True)\n",
    "print(\"Took {} seconds for prediction.\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>product</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151460</th>\n",
       "      <td>\"f6587c0b-ee2a-4bee-bbbd-d4d7f577e7ea\"</td>\n",
       "      <td>Buscomac Tab 10mg</td>\n",
       "      <td>-0.678197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151461</th>\n",
       "      <td>\"f6587c0b-ee2a-4bee-bbbd-d4d7f577e7ea\"</td>\n",
       "      <td>Dicnac Diclofenac 50mg Tablets x10</td>\n",
       "      <td>-3.891816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151462</th>\n",
       "      <td>\"f6587c0b-ee2a-4bee-bbbd-d4d7f577e7ea\"</td>\n",
       "      <td>Folic acid + B12 Tablets (Dr Meyer's) x100</td>\n",
       "      <td>3.941303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151463</th>\n",
       "      <td>\"f6587c0b-ee2a-4bee-bbbd-d4d7f577e7ea\"</td>\n",
       "      <td>Benzyl benzoate 100ml</td>\n",
       "      <td>-0.761906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151464</th>\n",
       "      <td>\"f6587c0b-ee2a-4bee-bbbd-d4d7f577e7ea\"</td>\n",
       "      <td>Ulgicid 200ml Suspension</td>\n",
       "      <td>-0.067324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   location_id  \\\n",
       "151460  \"f6587c0b-ee2a-4bee-bbbd-d4d7f577e7ea\"   \n",
       "151461  \"f6587c0b-ee2a-4bee-bbbd-d4d7f577e7ea\"   \n",
       "151462  \"f6587c0b-ee2a-4bee-bbbd-d4d7f577e7ea\"   \n",
       "151463  \"f6587c0b-ee2a-4bee-bbbd-d4d7f577e7ea\"   \n",
       "151464  \"f6587c0b-ee2a-4bee-bbbd-d4d7f577e7ea\"   \n",
       "\n",
       "                                           product  prediction  \n",
       "151460                           Buscomac Tab 10mg   -0.678197  \n",
       "151461          Dicnac Diclofenac 50mg Tablets x10   -3.891816  \n",
       "151462  Folic acid + B12 Tablets (Dr Meyer's) x100    3.941303  \n",
       "151463                       Benzyl benzoate 100ml   -0.761906  \n",
       "151464                    Ulgicid 200ml Suspension   -0.067324  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>product</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>650764</th>\n",
       "      <td>\"04f7dedc-48c3-4568-b758-6e877e6aec15\"</td>\n",
       "      <td>Super Apeti 2 x 10 Tablets</td>\n",
       "      <td>-5.812007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542149</th>\n",
       "      <td>\"a8962afb-c3ba-452c-ab86-151ec6bef88f\"</td>\n",
       "      <td>Nivea Lotion Body Natural Fairness 250ml</td>\n",
       "      <td>-5.705727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163007</th>\n",
       "      <td>\"b716103f-75f5-489d-a5cf-e1bce75287e6\"</td>\n",
       "      <td>Nivea Lotion Body Natural Fairness 250ml</td>\n",
       "      <td>-5.493479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533019</th>\n",
       "      <td>\"2f72781d-28d9-4bd0-867e-d8a0099fa803\"</td>\n",
       "      <td>Orelox 40mg/5ml Suspension 100ml</td>\n",
       "      <td>-5.484428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663942</th>\n",
       "      <td>\"df8325ba-a6a4-4129-a7e2-1c083905b76a\"</td>\n",
       "      <td>Flagentyl 500mg Tablets x4</td>\n",
       "      <td>-5.457555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   location_id  \\\n",
       "650764  \"04f7dedc-48c3-4568-b758-6e877e6aec15\"   \n",
       "542149  \"a8962afb-c3ba-452c-ab86-151ec6bef88f\"   \n",
       "163007  \"b716103f-75f5-489d-a5cf-e1bce75287e6\"   \n",
       "533019  \"2f72781d-28d9-4bd0-867e-d8a0099fa803\"   \n",
       "663942  \"df8325ba-a6a4-4129-a7e2-1c083905b76a\"   \n",
       "\n",
       "                                         product  prediction  \n",
       "650764                Super Apeti 2 x 10 Tablets   -5.812007  \n",
       "542149  Nivea Lotion Body Natural Fairness 250ml   -5.705727  \n",
       "163007  Nivea Lotion Body Natural Fairness 250ml   -5.493479  \n",
       "533019          Orelox 40mg/5ml Suspension 100ml   -5.484428  \n",
       "663942                Flagentyl 500mg Tablets x4   -5.457555  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore min\n",
    "all_predictions.sort_values(by=\"prediction\", ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>product</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1344806</th>\n",
       "      <td>\"1319c26d-58dc-41a2-9d2c-f93bab659048\"</td>\n",
       "      <td>Orheptal Tonic 300ml</td>\n",
       "      <td>7.351610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939274</th>\n",
       "      <td>\"11e29a4a-081d-4c6a-aa7b-9ad4bf6b794c\"</td>\n",
       "      <td>Orheptal Tonic 100ml</td>\n",
       "      <td>7.269585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389646</th>\n",
       "      <td>\"80137059-7695-40c8-ae98-4bab39ccf2d4\"</td>\n",
       "      <td>Lofnac Tablets x10</td>\n",
       "      <td>7.204725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182435</th>\n",
       "      <td>\"be680c27-8202-46d3-9719-19500a52206b\"</td>\n",
       "      <td>Cotton wool 100g</td>\n",
       "      <td>7.183845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753993</th>\n",
       "      <td>\"0ce6b16d-0e5a-4cd6-9ccc-70d81037c72a\"</td>\n",
       "      <td>Orheptal Tonic 300ml</td>\n",
       "      <td>7.168321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    location_id               product  \\\n",
       "1344806  \"1319c26d-58dc-41a2-9d2c-f93bab659048\"  Orheptal Tonic 300ml   \n",
       "939274   \"11e29a4a-081d-4c6a-aa7b-9ad4bf6b794c\"  Orheptal Tonic 100ml   \n",
       "389646   \"80137059-7695-40c8-ae98-4bab39ccf2d4\"    Lofnac Tablets x10   \n",
       "1182435  \"be680c27-8202-46d3-9719-19500a52206b\"      Cotton wool 100g   \n",
       "753993   \"0ce6b16d-0e5a-4cd6-9ccc-70d81037c72a\"  Orheptal Tonic 300ml   \n",
       "\n",
       "         prediction  \n",
       "1344806    7.351610  \n",
       "939274     7.269585  \n",
       "389646     7.204725  \n",
       "1182435    7.183845  \n",
       "753993     7.168321  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore max\n",
    "all_predictions.sort_values(by=\"prediction\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Evaluation / Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_map = map_at_k(test, all_predictions, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_SPLIT_TRAIN_TEST)\n",
    "# eval_ndcg = ndcg_at_k(test, all_predictions, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_SPLIT_TRAIN_TEST)\n",
    "# eval_rndcg = rndcg_at_k(test, all_predictions, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_SPLIT_TRAIN_TEST, rndcg_multiplier=RNDCG_MULTIPLIER)\n",
    "# eval_precision = precision_at_k(test, all_predictions, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_SPLIT_TRAIN_TEST)\n",
    "# eval_recall = recall_at_k(test, all_predictions, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_SPLIT_TRAIN_TEST)\n",
    "\n",
    "# print(\"MAP:\\t%f\" % eval_map,\n",
    "#       \"NDCG:\\t%f\" % eval_ndcg,\n",
    "#       \"RNDCG:\\t%f\" % eval_rndcg,\n",
    "#       \"Precision@K:\\t%f\" % eval_precision,\n",
    "#       \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Train, Predict, and Evaluate on Whole Dataset\n",
    "\n",
    "Earlier, we had split train (for model training) and test (for evaluation). In implementation, we have train = whole dataset, and we can evaluate on test = whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DanielShen/opt/anaconda3/envs/microsoft_rec/lib/python3.8/site-packages/cornac/data/dataset.py:361: UserWarning: 570 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 960\n",
      "Number of items: 2099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 21.14it/s, correct=97.10%, skipped=14.53%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished!\n",
      "Took 4.7947 seconds for training.\n",
      "Took 0.4430 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "## Data\n",
    "data_set = cornac.data.Dataset.from_uir(data.itertuples(index=False), seed=SEED)\n",
    "print('Number of users: {}'.format(data_set.num_users))\n",
    "print('Number of items: {}'.format(data_set.num_items))\n",
    "\n",
    "## Train\n",
    "bpr_whole = cornac.models.BPR(\n",
    "    k=NUM_FACTORS,\n",
    "    max_iter=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    lambda_reg=LAMBDA_REG,\n",
    "    verbose=True,\n",
    "    seed=SEED\n",
    ")\n",
    "with Timer() as t:\n",
    "    bpr_whole.fit(data_set)\n",
    "print(\"Took {} seconds for training.\".format(t))\n",
    "\n",
    "## Predict\n",
    "with Timer() as t:\n",
    "    all_predictions_whole = predict_ranking(bpr_whole, data, usercol=COL_USER, itemcol=COL_ITEM, remove_seen=False)\n",
    "print(\"Took {} seconds for prediction.\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>product</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7952</th>\n",
       "      <td>\"04f7dedc-48c3-4568-b758-6e877e6aec15\"</td>\n",
       "      <td>Super Apeti 2 x 10 Tablets</td>\n",
       "      <td>-7.389133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>\"04f7dedc-48c3-4568-b758-6e877e6aec15\"</td>\n",
       "      <td>Piscof Syrup</td>\n",
       "      <td>-7.049437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7849</th>\n",
       "      <td>\"04f7dedc-48c3-4568-b758-6e877e6aec15\"</td>\n",
       "      <td>Maxiquine Tablets x 10</td>\n",
       "      <td>-6.610123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862245</th>\n",
       "      <td>\"2df94bfb-4f8b-411c-9411-99c4889193c7\"</td>\n",
       "      <td>Super Apeti 2 x 10 Tablets</td>\n",
       "      <td>-6.463717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333276</th>\n",
       "      <td>\"2f72781d-28d9-4bd0-867e-d8a0099fa803\"</td>\n",
       "      <td>Orelox 40mg/5ml Suspension 100ml</td>\n",
       "      <td>-6.439687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    location_id  \\\n",
       "7952     \"04f7dedc-48c3-4568-b758-6e877e6aec15\"   \n",
       "7871     \"04f7dedc-48c3-4568-b758-6e877e6aec15\"   \n",
       "7849     \"04f7dedc-48c3-4568-b758-6e877e6aec15\"   \n",
       "862245   \"2df94bfb-4f8b-411c-9411-99c4889193c7\"   \n",
       "1333276  \"2f72781d-28d9-4bd0-867e-d8a0099fa803\"   \n",
       "\n",
       "                                  product  prediction  \n",
       "7952           Super Apeti 2 x 10 Tablets   -7.389133  \n",
       "7871                         Piscof Syrup   -7.049437  \n",
       "7849               Maxiquine Tablets x 10   -6.610123  \n",
       "862245         Super Apeti 2 x 10 Tablets   -6.463717  \n",
       "1333276  Orelox 40mg/5ml Suspension 100ml   -6.439687  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore min\n",
    "all_predictions_whole.sort_values(by=\"prediction\", ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>product</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1431695</th>\n",
       "      <td>\"c892df4f-ae29-4b8c-85cf-e7914c7a3f0e\"</td>\n",
       "      <td>Ampiclox (Unbranded) 500mg Capsules x100</td>\n",
       "      <td>9.714970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860792</th>\n",
       "      <td>\"2df94bfb-4f8b-411c-9411-99c4889193c7\"</td>\n",
       "      <td>Amoxil (Beecham) 500mg Capsules</td>\n",
       "      <td>9.567314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566924</th>\n",
       "      <td>\"8b948640-84fe-4b5b-98e6-18d5c1cee21a\"</td>\n",
       "      <td>Bunto Blood Caps x100</td>\n",
       "      <td>9.509598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333804</th>\n",
       "      <td>\"2f72781d-28d9-4bd0-867e-d8a0099fa803\"</td>\n",
       "      <td>Curefenac 100mg</td>\n",
       "      <td>9.401714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575320</th>\n",
       "      <td>\"90a24bab-3aed-4383-9509-b0ee96045cd6\"</td>\n",
       "      <td>Bunto Blood Caps x100</td>\n",
       "      <td>9.319536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    location_id  \\\n",
       "1431695  \"c892df4f-ae29-4b8c-85cf-e7914c7a3f0e\"   \n",
       "860792   \"2df94bfb-4f8b-411c-9411-99c4889193c7\"   \n",
       "566924   \"8b948640-84fe-4b5b-98e6-18d5c1cee21a\"   \n",
       "1333804  \"2f72781d-28d9-4bd0-867e-d8a0099fa803\"   \n",
       "575320   \"90a24bab-3aed-4383-9509-b0ee96045cd6\"   \n",
       "\n",
       "                                          product  prediction  \n",
       "1431695  Ampiclox (Unbranded) 500mg Capsules x100    9.714970  \n",
       "860792            Amoxil (Beecham) 500mg Capsules    9.567314  \n",
       "566924                      Bunto Blood Caps x100    9.509598  \n",
       "1333804                           Curefenac 100mg    9.401714  \n",
       "575320                      Bunto Blood Caps x100    9.319536  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore max\n",
    "all_predictions_whole.sort_values(by=\"prediction\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP_K_WHOLE = 100\n",
    "# RNDCG_MULTIPLIER = 3\n",
    "\n",
    "## Evaluate\n",
    "# eval_map_whole = map_at_k(data, all_predictions_whole, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_WHOLE)\n",
    "# eval_ndcg_whole = ndcg_at_k(data, all_predictions_whole, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_WHOLE)\n",
    "# eval_rndcg_whole = rndcg_at_k(data, all_predictions_whole, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_WHOLE, rndcg_multiplier=RNDCG_MULTIPLIER)\n",
    "# eval_precision_whole = precision_at_k(data, all_predictions_whole, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_WHOLE)\n",
    "# eval_recall_whole = recall_at_k(data, all_predictions_whole, col_user=COL_USER, col_item=COL_ITEM, col_rating=COL_RATING, k=TOP_K_WHOLE)\n",
    "\n",
    "# print(\"MAP:\\t%f\" % eval_map_whole,\n",
    "#       \"NDCG:\\t%f\" % eval_ndcg_whole,\n",
    "#       \"RNDCG:\\t%f\" % eval_rndcg_whole,\n",
    "#       \"Precision@K:\\t%f\" % eval_precision_whole,\n",
    "#       \"Recall@K:\\t%f\" % eval_recall_whole, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE_ALL_RECS = True\n",
    "# SAVE_NEW_RECS = True\n",
    "\n",
    "## Save recommendations\n",
    "# if SAVE_ALL_RECS:\n",
    "#     top_k_predictions_whole = get_top_k_items(all_predictions_whole, col_user=COL_USER, col_rating=DEFAULT_PREDICTION_COL, k=TOP_K_WHOLE)\n",
    "#     top_k_predictions_whole.drop(DEFAULT_PREDICTION_COL, axis = 1, inplace = True)\n",
    "#     # add column of true sales and rank of predicted products\n",
    "#     top_all_true = get_top_k_items(data, col_user=COL_USER, col_rating=COL_RATING, k=data_set.num_items)\n",
    "#     top_k_predictions_whole = top_k_predictions_whole.merge(top_all_true, how = 'left', on = [COL_USER, COL_ITEM], suffixes = (None, \"_true\"))\n",
    "#     top_k_predictions_whole[\"rank_true\"] = top_k_predictions_whole[\"rank_true\"].convert_dtypes()\n",
    "#     top_k_predictions_whole.rename(columns = {COL_ITEM: \"predicted \" + COL_ITEM, COL_RATING: \"predicted \" + COL_ITEM + \"'s true \" + COL_RATING, \"rank_true\": \"predicted \" + COL_ITEM + \"'s true rank\"}, inplace = True)\n",
    "#     # add columns of true top-ranked products\n",
    "#     top_all_true.rename(columns = {COL_ITEM: \"true \" + COL_ITEM, COL_RATING: \"true \"  + COL_ITEM + \"'s \" + COL_RATING}, inplace = True)\n",
    "#     top_k_predictions_whole = top_k_predictions_whole.merge(top_all_true, how = 'left', on = [COL_USER, 'rank'])\n",
    "#     # reorder columns\n",
    "#     top_k_predictions_whole = top_k_predictions_whole[[COL_USER, \"rank\", \"true \" + COL_ITEM, \"true \" + COL_ITEM + \"'s \" + COL_RATING, \"predicted \" + COL_ITEM, \"predicted \"  + COL_ITEM + \"'s true \" + COL_RATING, \"predicted \" + COL_ITEM + \"'s true rank\"]]\n",
    "#     # save to csv\n",
    "#     top_k_predictions_whole.to_csv(THIS_ENGINE_NAME + \"_\" + COUNTRY + \"_top_\" + str(TOP_K_WHOLE) + \"_all_prod_recs.csv\")\n",
    "# if SAVE_NEW_RECS:\n",
    "#     new_predictions_whole = all_predictions_whole.merge(data, on=[COL_USER,COL_ITEM], indicator=True, how=\"left\").query('_merge==\"left_only\"').drop('_merge', axis=1).drop([COL_RATING], axis=1)\n",
    "#     top_k_predictions_whole = get_top_k_items(new_predictions_whole, col_user=COL_USER, col_rating=DEFAULT_PREDICTION_COL, k=TOP_K_WHOLE)\n",
    "#     top_k_predictions_whole.drop(DEFAULT_PREDICTION_COL, axis = 1, inplace = True)\n",
    "#     top_k_predictions_whole.rename(columns = {COL_ITEM: \"predicted new \" + COL_ITEM}, inplace=True)\n",
    "#     top_k_true = get_top_k_items(data, col_user=COL_USER, col_rating=COL_RATING, k=TOP_K_WHOLE)\n",
    "#     top_k_true.rename(columns = {COL_ITEM: \"true \" + COL_ITEM, COL_RATING: \"true \"  + COL_ITEM + \"'s \" + COL_RATING}, inplace = True)\n",
    "#     top_k_predictions_whole = top_k_predictions_whole.merge(top_k_true, on = [COL_USER, 'rank'])\n",
    "#     top_k_predictions_whole = top_k_predictions_whole[[COL_USER, \"rank\", \"true \" + COL_ITEM, \"true \" + COL_ITEM + \"'s \" + COL_RATING, \"predicted new \" + COL_ITEM]]\n",
    "#     top_k_predictions_whole.to_csv(THIS_ENGINE_NAME + \"_\" + COUNTRY + \"_top_\" + str(TOP_K_WHOLE) + \"_new_prod_recs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
